Let's create an Agent to chat with qif/csv files using PandasAI and Ollama running LLM Phi4-mini:3.8b or similar, locally.  The runtime machine is my laptop,with processor Snapdragon(R) X 12-core, ARM64.  THe project should run in local Docker, which is already installed.  Also, Ollama is already running with LLM Phi4:mini:3.8b or similar LLM.  Do deep research and provide all the necessary files and code for the project.  Also provide the project directory structure.  Ensure all code follows best practices for python and Docker.  Remember, no app data or API calls should use the Internet.  All queries must be processed locally.
